{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary libraries of pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/19 20:49:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"demo\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.option('header',\"true\").csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+\n",
      "|   name|age|     city|\n",
      "+-------+---+---------+\n",
      "| Manish| 26|Darbhangs|\n",
      "| Ambika| 25|Gorakhpur|\n",
      "|Chandra| 26|   Bareli|\n",
      "+-------+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.option('header',\"true\").csv(\"data.csv\",inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'city']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Manish', age=26, city='Darbhangs'),\n",
       " Row(name='Ambika', age=25, city='Gorakhpur'),\n",
       " Row(name='Chandra', age=26, city='Bareli')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "| Manish|\n",
      "| Ambika|\n",
      "|Chandra|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select('name'))c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select('name','age'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: int]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(['name','age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "| Manish| 26|\n",
      "| Ambika| 25|\n",
      "|Chandra| 26|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['name','age']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int'), ('city', 'string')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, name: string, age: string, city: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+---------+\n",
      "|summary|  name|               age|     city|\n",
      "+-------+------+------------------+---------+\n",
      "|  count|     3|                 3|        3|\n",
      "|   mean|  null|25.666666666666668|     null|\n",
      "| stddev|  null|0.5773502691896258|     null|\n",
      "|    min|Ambika|                25|   Bareli|\n",
      "|    max|Manish|                26|Gorakhpur|\n",
      "+-------+------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Dataframe in columns\n",
    "from pyspark.sql.functions import lit\n",
    "df.withColumn('Experience',lit([1,3,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying pyspark functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"app\").master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+--------------+\n",
      "|col_name|col_company|col_salary|col_department|\n",
      "+--------+-----------+----------+--------------+\n",
      "|   Anand|       null|        -2|           R&D|\n",
      "|  Naveen|      Cisco|   2000000|           R&D|\n",
      "|   Pawan|     Cerner|   2100000|          null|\n",
      "|    null|        IBM|      null|          null|\n",
      "|  Girish|       null|        -1|          null|\n",
      "| Kishore|        TCS|      null|          null|\n",
      "|    null|    Ericson|      null|          null|\n",
      "|    null|       null|      null|          null|\n",
      "|    null|       null|        -1|          null|\n",
      "+--------+-----------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(path=\"data/employee-missing-records.dat\",header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col_name: string (nullable = true)\n",
      " |-- col_company: string (nullable = true)\n",
      " |-- col_salary: string (nullable = true)\n",
      " |-- col_department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+--------------+\n",
      "|col_name|col_company|col_salary|col_department|\n",
      "+--------+-----------+----------+--------------+\n",
      "|  Naveen|      Cisco|   2000000|           R&D|\n",
      "+--------+-----------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+--------------+\n",
      "|col_name|col_company|col_salary|col_department|\n",
      "+--------+-----------+----------+--------------+\n",
      "|  Naveen|      Cisco|   2000000|           R&D|\n",
      "+--------+-----------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Both the function are giving the same output\n",
    "\n",
    "df.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+--------------+\n",
      "|col_name|col_company|col_salary|col_department|\n",
      "+--------+-----------+----------+--------------+\n",
      "|   Anand|       null|        -2|           R&D|\n",
      "|  Naveen|      Cisco|   2000000|           R&D|\n",
      "|   Pawan|     Cerner|   2100000|          null|\n",
      "|  Girish|       null|        -1|          null|\n",
      "| Kishore|        TCS|      null|          null|\n",
      "+--------+-----------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset=\"col_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+--------------+\n",
      "|col_name|col_company|col_salary|col_department|\n",
      "+--------+-----------+----------+--------------+\n",
      "|   Anand|       null|        -2|           R&D|\n",
      "|  Naveen|      Cisco|   2000000|           R&D|\n",
      "|   Pawan|     Cerner|   2100000|          null|\n",
      "|    null|        IBM|      null|          null|\n",
      "|  Girish|       null|        -1|          null|\n",
      "| Kishore|        TCS|      null|          null|\n",
      "|    null|    Ericson|      null|          null|\n",
      "|    null|       null|      null|          null|\n",
      "|    null|       null|        -1|          null|\n",
      "+--------+-----------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------+--------------+\n",
      "|      col_name|   col_company|    col_salary|col_department|\n",
      "+--------------+--------------+--------------+--------------+\n",
      "|         Anand|NULL IN SOURCE|            -2|           R&D|\n",
      "|        Naveen|         Cisco|       2000000|           R&D|\n",
      "|         Pawan|        Cerner|       2100000|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|           IBM|NULL IN SOURCE|NULL IN SOURCE|\n",
      "|        Girish|NULL IN SOURCE|            -1|NULL IN SOURCE|\n",
      "|       Kishore|           TCS|NULL IN SOURCE|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|       Ericson|NULL IN SOURCE|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|NULL IN SOURCE|NULL IN SOURCE|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|NULL IN SOURCE|            -1|NULL IN SOURCE|\n",
      "+--------------+--------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(\"NULL IN SOURCE\").na.fill(0).na.replace(-1,1).show()\n",
    "#its not repalacing -1 to 1 due to data type of col_salary is string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[col_name: string, col_company: string, col_salary: int, col_department: string]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumn(\"col_salary\", col(\"col_salary\").cast(\"int\"))\n",
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+----------+--------------+\n",
      "|      col_name|   col_company|col_salary|col_department|\n",
      "+--------------+--------------+----------+--------------+\n",
      "|         Anand|NULL IN SOURCE|         2|           R&D|\n",
      "|        Naveen|         Cisco|   2000000|           R&D|\n",
      "|         Pawan|        Cerner|   2100000|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|           IBM|         0|NULL IN SOURCE|\n",
      "|        Girish|NULL IN SOURCE|         1|NULL IN SOURCE|\n",
      "|       Kishore|           TCS|         0|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|       Ericson|         0|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|NULL IN SOURCE|         0|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|NULL IN SOURCE|         1|NULL IN SOURCE|\n",
      "+--------------+--------------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "   df.na.fill(\"NULL IN SOURCE\").na.fill(0).na.replace(-1, 1, subset=[\"col_salary\"]).na.replace(-2, 2, subset=[\n",
    "       \"col_salary\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+----------+--------------+\n",
      "|      col_name|   col_company|col_salary|col_department|\n",
      "+--------------+--------------+----------+--------------+\n",
      "|         Anand|NULL IN SOURCE|        -2|           R&D|\n",
      "|        Naveen|         Cisco|   2000000|           R&D|\n",
      "|         Pawan|        Cerner|   2100000|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|           IBM|         0|NULL IN SOURCE|\n",
      "|        Girish|NULL IN SOURCE|         1|NULL IN SOURCE|\n",
      "|       Kishore|           TCS|         0|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|       Ericson|         0|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|NULL IN SOURCE|         0|NULL IN SOURCE|\n",
      "|NULL IN SOURCE|NULL IN SOURCE|         1|NULL IN SOURCE|\n",
      "+--------------+--------------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(\"NULL IN SOURCE\").na.fill(0).na.replace(-1,1, subset=[\"col_salary\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert to int datatype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# create a sample DataFrame with a string column\n",
    "data = [(\"1\", \"John\"), (\"2\", \"Jane\"), (\"3\", \"Bob\")]\n",
    "df1 = spark.createDataFrame(data, [\"id\", \"name\"])\n",
    "df1.printSchema()\n",
    "\n",
    "\n",
    "# cast the 'id' column to an integer datatype\n",
    "df1 = df1.withColumn(\"id\", col(\"id\").cast(\"int\"))\n",
    "\n",
    "# print the schema of the DataFrame\n",
    "df1.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDF - User Defined Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,col\n",
    "from pyspark.sql.types import StringType\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_case(str):\n",
    "    return str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "str=\"manish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Manish'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_case(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"app\").master(\"local\").getOrCreate()\n",
    "\n",
    "data = [(1,\"manish kumar\"), (2, \"avnish tiwari\"), (3,\"sahil yadav\")]\n",
    "df = spark.createDataFrame(data,schema=(\"id\",\"name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|         name|\n",
      "+---+-------------+\n",
      "|  1| manish kumar|\n",
      "|  2|avnish tiwari|\n",
      "|  3|  sahil yadav|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_title_case = udf(lambda x: convert_case(x),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|         Name|\n",
      "+-------------+\n",
      "| Manish Kumar|\n",
      "|Avnish Tiwari|\n",
      "|  Sahil Yadav|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(convert_to_title_case(col(\"name\")).alias(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
